---
title: "[Python] 데이터프레임 응용(2) - 열 재구성, 데이터프레임 합치기"
excerpt: "0605 데이터프레임 응용(2) - 열 재구성, 데이터프레임 합치기"

categories:
  - 데이터 분석
tags:
  - []

permalink: /DA/lesson7-1/

toc: true
toc_sticky: ture

date: 2023-06-05
last_modified_at: 2023-06-05
---

## 열 재구성

```python
# 데이터 불러오기
import seaborn as sns
titanic = sns.load_dataset('titanic')

# 열 선택
df = titanic.loc[:, 'survived':'age']
df.head()
---------------------------------------
# 	survived	pclass	sex	age
# 0	0	3	male	22.0
# 1	1	1	female	38.0
# 2	1	3	female	26.0
# 3	1	1	female	35.0
# 4	0	3	male	35.0
```

### 열 순서 변경

- 열 이름 알파벳 순서대로 정렬 = 오름차순

```python
columns = df.columns.values
columns_asc = sorted(columns)

df[columns_asc].head()
# = df[['age','pclass','sex','survived']]
------------------------------------
# 	age	pclass	sex	survived
# 0	22.0	3	male	0
# 1	38.0	1	female	1
# 2	26.0	3	female	1
# 3	35.0	1	female	1
# 4	35.0	3	male	0
```

- 내림차순 - 열 순서를 반대로

```python
columns_dsc = list(reversed(columns_asc))
df[columns_dsc].head()
------------------------------------
# 	survived	sex	pclass	age
# 0	0	male	3	22.0
# 1	1	female	1	38.0
# 2	1	female	3	26.0
# 3	1	female	1	35.0
# 4	0	male	3	35.0
```
- 열 순서를 사용자 마음대로 변경

```python
columns_modify = ['sex','age','pclass','survived']
df[columns_modify].head()
------------------------------------
# 	sex	age	pclass	survived
# 0	male	22.0	3	0
# 1	female	38.0	1	1
# 2	female	26.0	3	1
# 3	female	35.0	1	1
# 4	male	35.0	3	0
```

### 불 인덱싱

- 나이가 10세 이상 & 20세 미만인 고객 = 10대 고객

```python
age1 = (titanic['age'] >= 10) & (titanic['age'] < 20)
df_1 = titanic.loc[age1,:]
df_1.head()
------------------------------------------------------------------------------------------------------------------------------------------------------------------
# 	survived	pclass	sex	age	sibsp	parch	fare	embarked	class	who	adult_male	deck	embark_town	alive	alone
# 9	1	2	female	14.0	1	0	30.0708	C	Second	child	False	NaN	Cherbourg	yes	False
# 14	0	3	female	14.0	0	0	7.8542	S	Third	child	False	NaN	Southampton	no	True
# 22	1	3	female	15.0	0	0	8.0292	Q	Third	child	False	NaN	Queenstown	yes	True
# 27	0	1	male	19.0	3	2	263.0000	S	First	man	True	C	Southampton	no	False
# 38	0	3	female	18.0	2	0	18.0000	S	Third	woman	False	NaN	Southampton	no	False
```

- 나이가 10세 미만 & 성별이 여성인 고객 = 10세 미만 여자아이

```python
age2 = (titanic['age'] < 10) & (titanic['sex'] == 'female')
df2 = titanic.loc[age2,:]
df2.head()
------------------------------------------------------------------------------------------------------------------------------------------------------------------
# 	survived	pclass	sex	age	sibsp	parch	fare	embarked	class	who	adult_male	deck	embark_town	alive	alone
# 10	1	3	female	4.0	1	1	16.7000	S	Third	child	False	G	Southampton	yes	False
# 24	0	3	female	8.0	3	1	21.0750	S	Third	child	False	NaN	Southampton	no	False
# 43	1	2	female	3.0	1	2	41.5792	C	Second	child	False	NaN	Cherbourg	yes	False
# 58	1	2	female	5.0	1	2	27.7500	S	Second	child	False	NaN	Southampton	yes	False
# 119	0	3	female	2.0	4	2	31.2750	S	Third	child	False	NaN	Southampton	no	False
```

- 나이가 10세 미만 or 성별이 여성인 고객

```python
age3 = (titanic['age'] < 10) | (titanic['sex'] == 'female')
df3 = titanic.loc[age2,:]
df3.head()
------------------------------------------------------------------------------------------------------------------------------------------------------------------
# 	survived	pclass	sex	age	sibsp	parch	fare	embarked	class	who	adult_male	deck	embark_town	alive	alone
# 1	1	1	female	38.0	1	0	71.2833	C	First	woman	False	C	Cherbourg	yes	False
# 2	1	3	female	26.0	0	0	7.9250	S	Third	woman	False	NaN	Southampton	yes	True
# 3	1	1	female	35.0	1	0	53.1000	S	First	woman	False	C	Southampton	yes	False
# 7	0	3	male	2.0	3	1	21.0750	S	Third	child	False	NaN	Southampton	no	False
# 8	1	3	female	27.0	0	2	11.1333	S	Third	woman	False	NaN	Southampton	yes	False
```

### isin
- sibsp가 3,4,5인 고객

```python
sib = titanic['sibsp'].isin([3,4,5])
df_sb2 = titanic[sib]
df_sb2.head()
--------------------------------------------
# survived	pclass	sex	age	sibsp	parch	fare	embarked	class	who	adult_male	deck	embark_town	alive	alone
# 7	0	3	male	2.0	3	1	21.0750	S	Third	child	False	NaN	Southampton	no	False
# 16	0	3	male	2.0	4	1	29.1250	Q	Third	child	False	NaN	Queenstown	no	False
# 24	0	3	female	8.0	3	1	21.0750	S	Third	child	False	NaN	Southampton	no	False
# 27	0	1	male	19.0	3	2	263.0000	S	First	man	True	C	Southampton	no	False
# 50	0	3	male	7.0	4	1	39.6875	S	Third	child	False	NaN	Southampton	no	False
```

***


## 데이터프레임 합치기

```python
import pandas as pd
df1 = pd.DataFrame({'a': [1,2,3,4],
                    'b': [11,12,13,14],
                    'c': [21,22,23,24]})
df2 = pd.DataFrame({'a': [9,8,7],
                    'b': [19,18,17],
                    'c': [29,28,27],
                    'd': [39,38,37]})
print(df1)
print(df2)
--------------------------------
#    a   b   c
# 0  1  11  21
# 1  2  12  22
# 2  3  13  23
# 3  4  14  24

#    a   b   c   d
# 0  9  19  29  39
# 1  8  18  28  38
# 2  7  17  27  37
```
### Concat 연결

`cocnat(axis = 0)`: 위아래로 합치기   
`cocnat(axis = 1)`: 좌우로 합치기 

#### 데이터프레임과 데이터프레임 연결

- 기본값 => `axis = 0, join = 'outer'`

```python
pd.concat([df1,df2])
----------------------------
# 	a	b	c	d
# 0	1	11	21	NaN
# 1	2	12	22	NaN
# 2	3	13	23	NaN
# 3	4	14	24	NaN
# 0	9	19	29	39.0
# 1	8	18	28	38.0
# 2	7	17	27	37.0
```

- `axis = 0, join = 'inner'`

```python
pd.concat([df1,df2], join = 'inner')
----------------------------------
# 	a	b	c
# 0	1	11	21
# 1	2	12	22
# 2	3	13	23
# 3	4	14	24
# 0	9	19	29
# 1	8	18	28
# 2	7	17	27
```

- `axis = 0, join = 'inner'` & `행 인덱스 초기화`

```python
pd.concat([df1,df2], join = 'inner', ignore_index = True)
-----------------------------------------------------
# 	a	b	c
# 0	1	11	21
# 1	2	12	22
# 2	3	13	23
# 3	4	14	24
# 4	9	19	29
# 5	8	18	28
# 6	7	17	27
```

- `axis = 1, join = 'outer'`

```python
pd.concat([df1,df2], axis = 1)
------------------------------
# 	a	b	c	a	b	c	d
# 0	1	11	21	9.0	19.0	29.0	39.0
# 1	2	12	22	8.0	18.0	28.0	38.0
# 2	3	13	23	7.0	17.0	27.0	37.0
# 3	4	14	24	NaN	NaN	NaN	NaN
```

- `axis = 1, join = 'inner'`

```python
pd.concat([df1,df2], axis = 1, join = 'inner')
-------------------------------------------------------
# 	a	b	c	a	b	c	d
# 0	1	11	21	9	19	29	39
# 1	2	12	22	8	18	28	38
# 2	3	13	23	7	17	27	37
```

#### 데이터프레임과 시리즈 연결

```python
sr1 = pd.Series([4,5,6,7], name = 'e')
sr2 = pd.Series([14,15,16,17], name = 'f', index = [1,2,3,4])
sr3 = pd.Series([24,25,26,27], name = 'g')
```

- `axis = 1, join = 'outer'`

```python
# 시리즈의 이름이 열 이름
print(df1)
pd.concat([df1,sr1],axis = 1)
-----------------------------
#    a   b   c
# 0  1  11  21
# 1  2  12  22
# 2  3  13  23
# 3  4  14  24

# 	a	b	c	e
# 0	1	11	21	4
# 1	2	12	22	5
# 2	3	13	23	6
# 3	4	14	24	7


# 없는 인덱스인 경우에는 Nan
print(df2)
pd.concat([df2,sr2],axis = 1)
--------------------------------
#    a   b   c   d
# 0  9  19  29  39
# 1  8  18  28  38
# 2  7  17  27  37

# 	a	b	c	d	f
# 0	9.0	19.0	29.0	39.0	NaN
# 1	8.0	18.0	28.0	38.0	14.0
# 2	7.0	17.0	27.0	37.0	15.0
# 3	NaN	NaN	NaN	NaN	16.0
# 4	NaN	NaN	NaN	NaN	17.0
```

- `axis = 1, join = 'inner'`

```python
# 행 인덱스가 같은 것끼리 연결 => 공통된 행만 추출
print(df2)
pd.concat([df2,sr2],axis = 1, join = 'inner')
------------------------------------
#    a   b   c   d
# 0  9  19  29  39
# 1  8  18  28  38
# 2  7  17  27  37

# 	a	b	c	d	f
# 1	8	18	28	38	14
# 2	7	17	27	37	15
```

- 인덱스를 랜덤하게 설정

```python
df3 = pd.DataFrame({'a': [9,8,7],
                    'b': [19,18,17],
                    'c': [29,28,27],
                    'd': [39,38,37]}, index = [4,3,2])
```

```python
# df3 인덱스 번호 순서대로 합쳐짐 = 4, 3, 2
print(df3)
pd.concat([df3,sr2], axis = 1)
----------------------------------------
#    a   b   c   d
# 4  9  19  29  39
# 3  8  18  28  38
# 2  7  17  27  37

# 	a	b	c	d	f
# 4	9.0	19.0	29.0	39.0	17
# 3	8.0	18.0	28.0	38.0	16
# 2	7.0	17.0	27.0	37.0	15
# 1	NaN	NaN	NaN	NaN	14


# sort = True로 설정하면 인덱스 번호가 오름차순으로 정렬
pd.concat([df3,sr2], axis = 1, sort = True)
----------------------------------------------
# 	a	b	c	d	f
# 1	NaN	NaN	NaN	NaN	14
# 2	7.0	17.0	27.0	37.0	15
# 3	8.0	18.0	28.0	38.0	16
# 4	9.0	19.0	29.0	39.0	17
```

#### 시리즈와 시리즈 연결

`sr1 + sr2`

```python
pd.concat([sr1,sr2], axis = 0)
---------------------------------
# 0     4
# 1     5
# 2     6
# 3     7
# 1    14
# 2    15
# 3    16
# 4    17
# dtype: int64

pd.concat([sr1,sr2], axis = 1)
-------------------------------------
# 	e	f
# 0	4.0	NaN
# 1	5.0	14.0
# 2	6.0	15.0
# 3	7.0	16.0
# 4	NaN	17.0

pd.concat([sr1,sr2], axis = 1, join = 'inner')
-----------------------------------
# 	e	f
# 1	5	14
# 2	6	15
# 3	7	16
```

`sr1 + sr3`

```python
pd.concat([sr1,sr3], axis = 0)
-----------------------------------------
# 0     4
# 1     5
# 2     6
# 3     7
# 0    24
# 1    25
# 2    26
# 3    27
# dtype: int64

pd.concat([sr1,sr3], axis = 1)
---------------------------------------
# 	e	g
# 0	4	24
# 1	5	25
# 2	6	26
# 3	7	27
```
### Merge 병합

SQL JON과 유사 = 좌우로 합치기 (병합)  
공통된 열, 인덱스 => 키  

```python
import pandas as pd
df1 = pd.read_excel('/content/drive/MyDrive/hana1/PYTHON/data/stock price.xlsx', engine = 'openpyxl')
df2 = pd.read_excel('/content/drive/MyDrive/hana1/PYTHON/data/stock valuation.xlsx', engine = 'openpyxl')

print(df1.head())
print(df2.head())
----------------------------------------------------
#        id stock_name          value   price
# 0  128940       한미약품   59385.666667  421000
# 1  130960     CJ E&M   58540.666667   98900
# 2  138250      엔에스쇼핑   14558.666667   13200
# 3  139480        이마트  239230.833333  254500
# 4  142280     녹십자엠에스     468.833333   10200

#        id     name           eps     bps        per       pbr
# 0  130960   CJ E&M   6301.333333   54068  15.695091  1.829178
# 1  136480       하림    274.166667    3551  11.489362  0.887074
# 2  138040  메리츠금융지주   2122.333333   14894   6.313806  0.899691
# 3  139480      이마트  18268.166667  295780  13.931338  0.860437
# 4  145990      삼양사   5741.000000  108090  14.283226  0.758627
```

- INNER JOIN

```python
# 기본값 how = 'inner', on = None (공통열)
pd.merge(df1,df2)
------------------------------------------------------------------------------------------------------------
# 	id	stock_name	value	price	name	eps	bps	per	pbr
# 0	130960	CJ E&M	58540.666667	98900	CJ E&M	6301.333333	54068	15.695091	1.829178
# 1	139480	이마트	239230.833333	254500	이마트	18268.166667	295780	13.931338	0.860437
# 2	145990	삼양사	82750.000000	82000	삼양사	5741.000000	108090	14.283226	0.758627
# 3	185750	종근당	40293.666667	100500	종근당	3990.333333	40684	25.185866	2.470259
# 4	204210	모두투어리츠	3093.333333	3475	모두투어리츠	85.166667	5335	40.802348	0.651359
```

- FULL OUTER JOIN

```python
pd.merge(df1,df2, how = 'outer', on = 'id')
------------------------------------------------------------------------------------------------------------
# 	id	stock_name	value	price	name	eps	bps	per	pbr
# 0	128940	한미약품	59385.666667	421000.0	NaN	NaN	NaN	NaN	NaN
# 1	130960	CJ E&M	58540.666667	98900.0	CJ E&M	6301.333333	54068.0	15.695091	1.829178
# 2	138250	엔에스쇼핑	14558.666667	13200.0	NaN	NaN	NaN	NaN	NaN
# 3	139480	이마트	239230.833333	254500.0	이마트	18268.166667	295780.0	13.931338	0.860437
# 4	142280	녹십자엠에스	468.833333	10200.0	NaN	NaN	NaN	NaN	NaN
# 5	145990	삼양사	82750.000000	82000.0	삼양사	5741.000000	108090.0	14.283226	0.758627
# 6	185750	종근당	40293.666667	100500.0	종근당	3990.333333	40684.0	25.185866	2.470259
# 7	192400	쿠쿠홀딩스	179204.666667	177500.0	NaN	NaN	NaN	NaN	NaN
# 8	199800	툴젠	-2514.333333	115400.0	NaN	NaN	NaN	NaN	NaN
# 9	204210	모두투어리츠	3093.333333	3475.0	모두투어리츠	85.166667	5335.0	40.802348	0.651359
# 10	136480	NaN	NaN	NaN	하림	274.166667	3551.0	11.489362	0.887074
# 11	138040	NaN	NaN	NaN	메리츠금융지주	2122.333333	14894.0	6.313806	0.899691
# 12	161390	NaN	NaN	NaN	한국타이어	5648.500000	51341.0	7.453306	0.820007
# 13	181710	NaN	NaN	NaN	NHN엔터테인먼트	2110.166667	78434.0	30.755864	0.827447
# 14	207940	NaN	NaN	NaN	삼성바이오로직스	4644.166667	60099.0	89.790059	6.938551
```

- LEFT OUTER JOIN

```python
pd.merge(df1,df2, how = 'left', on = 'id')
------------------------------------------------------------------------------------------------------------
# 	id	stock_name	value	price	name	eps	bps	per	pbr
# 0	128940	한미약품	59385.666667	421000	NaN	NaN	NaN	NaN	NaN
# 1	130960	CJ E&M	58540.666667	98900	CJ E&M	6301.333333	54068.0	15.695091	1.829178
# 2	138250	엔에스쇼핑	14558.666667	13200	NaN	NaN	NaN	NaN	NaN
# 3	139480	이마트	239230.833333	254500	이마트	18268.166667	295780.0	13.931338	0.860437
# 4	142280	녹십자엠에스	468.833333	10200	NaN	NaN	NaN	NaN	NaN
# 5	145990	삼양사	82750.000000	82000	삼양사	5741.000000	108090.0	14.283226	0.758627
# 6	185750	종근당	40293.666667	100500	종근당	3990.333333	40684.0	25.185866	2.470259
# 7	192400	쿠쿠홀딩스	179204.666667	177500	NaN	NaN	NaN	NaN	NaN
# 8	199800	툴젠	-2514.333333	115400	NaN	NaN	NaN	NaN	NaN
# 9	204210	모두투어리츠	3093.333333	3475	모두투어리츠	85.166667	5335.0	40.802348	0.651359
```

- RIGHT OUTER JOIN

```python
pd.merge(df1,df2, how = 'right', on = 'id')
------------------------------------------------------------------------------------------------------------
# 	id	stock_name	value	price	name	eps	bps	per	pbr
# 0	130960	CJ E&M	58540.666667	98900.0	CJ E&M	6301.333333	54068	15.695091	1.829178
# 1	136480	NaN	NaN	NaN	하림	274.166667	3551	11.489362	0.887074
# 2	138040	NaN	NaN	NaN	메리츠금융지주	2122.333333	14894	6.313806	0.899691
# 3	139480	이마트	239230.833333	254500.0	이마트	18268.166667	295780	13.931338	0.860437
# 4	145990	삼양사	82750.000000	82000.0	삼양사	5741.000000	108090	14.283226	0.758627
# 5	161390	NaN	NaN	NaN	한국타이어	5648.500000	51341	7.453306	0.820007
# 6	181710	NaN	NaN	NaN	NHN엔터테인먼트	2110.166667	78434	30.755864	0.827447
# 7	185750	종근당	40293.666667	100500.0	종근당	3990.333333	40684	25.185866	2.470259
# 8	204210	모두투어리츠	3093.333333	3475.0	모두투어리츠	85.166667	5335	40.802348	0.651359
# 9	207940	NaN	NaN	NaN	삼성바이오로직스	4644.166667	60099	89.790059	6.938551
```

### Join 결합

merge와 유사  
행 인덱스 기준으로 결합  
옵션을 지정하면 열 기준으로 결합 가능  

```python
# 행 인덱스 변경
df1.set_index('id', inplace = True)
df2.set_index('id', inplace = True)
```

- LEFT OUTER JOIN

```python
# 기본값 how = 'left'
join_left = df1.join(df2)
join_left
------------------------------------------------------------------------------------------------------------
# 	stock_name	value	price	name	eps	bps	per	pbr
# id								
# 128940	한미약품	59385.666667	421000	NaN	NaN	NaN	NaN	NaN
# 130960	CJ E&M	58540.666667	98900	CJ E&M	6301.333333	54068.0	15.695091	1.829178
# 138250	엔에스쇼핑	14558.666667	13200	NaN	NaN	NaN	NaN	NaN
# 139480	이마트	239230.833333	254500	이마트	18268.166667	295780.0	13.931338	0.860437
# 142280	녹십자엠에스	468.833333	10200	NaN	NaN	NaN	NaN	NaN
# 145990	삼양사	82750.000000	82000	삼양사	5741.000000	108090.0	14.283226	0.758627
# 185750	종근당	40293.666667	100500	종근당	3990.333333	40684.0	25.185866	2.470259
# 192400	쿠쿠홀딩스	179204.666667	177500	NaN	NaN	NaN	NaN	NaN
# 199800	툴젠	-2514.333333	115400	NaN	NaN	NaN	NaN	NaN
# 204210	모두투어리츠	3093.333333	3475	모두투어리츠	85.166667	5335.0	40.802348	0.651359
```

- RIGHT OUTER JOIN

```python
# 기본값 how = 'left'
join_right = df2.join(df1)
join_right
------------------------------------------------------------------------------------------------------------
# 	name	eps	bps	per	pbr	stock_name	value	price
# id								
# 130960	CJ E&M	6301.333333	54068	15.695091	1.829178	CJ E&M	58540.666667	98900.0
# 136480	하림	274.166667	3551	11.489362	0.887074	NaN	NaN	NaN
# 138040	메리츠금융지주	2122.333333	14894	6.313806	0.899691	NaN	NaN	NaN
# 139480	이마트	18268.166667	295780	13.931338	0.860437	이마트	239230.833333	254500.0
# 145990	삼양사	5741.000000	108090	14.283226	0.758627	삼양사	82750.000000	82000.0
# 161390	한국타이어	5648.500000	51341	7.453306	0.820007	NaN	NaN	NaN
# 181710	NHN엔터테인먼트	2110.166667	78434	30.755864	0.827447	NaN	NaN	NaN
# 185750	종근당	3990.333333	40684	25.185866	2.470259	종근당	40293.666667	100500.0
# 204210	모두투어리츠	85.166667	5335	40.802348	0.651359	모두투어리츠	3093.333333	3475.0
# 207940	삼성바이오로직스	4644.166667	60099	89.790059	6.938551	NaN	NaN	NaN
```

- INNER JOIN

```python
join_inner = df1.join(df2, how = 'inner')
join_inner
------------------------------------------------------------------------------------------------------------
# 	stock_name	value	price	name	eps	bps	per	pbr
# id								
# 130960	CJ E&M	58540.666667	98900	CJ E&M	6301.333333	54068	15.695091	1.829178
# 139480	이마트	239230.833333	254500	이마트	18268.166667	295780	13.931338	0.860437
# 145990	삼양사	82750.000000	82000	삼양사	5741.000000	108090	14.283226	0.758627
# 185750	종근당	40293.666667	100500	종근당	3990.333333	40684	25.185866	2.470259
# 204210	모두투어리츠	3093.333333	3475	모두투어리츠	85.166667	5335	40.802348	0.651359
```


